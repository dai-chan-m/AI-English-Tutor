// src/app/api/feedback/route.ts
import { NextRequest } from "next/server";
import { getOpenAIClient } from "@/utils/openaiClient";
import { createStreamResponse, handleAPIError } from "@/utils/apiErrorHandler";

const openai = getOpenAIClient();

// ãƒˆãƒ¼ãƒ³æŒ‡ç¤ºæ–‡ã‚’è¿”ã™é–¢æ•°
function getToneInstruction(tone: string): string {
  const toneMap: Record<string, string> = {
    gentle: "ä¸­å­¦ç”Ÿã«ã‚‚ã‚ã‹ã‚‹ã‚ˆã†ã«ã€ã‚„ã•ã—ãä¸å¯§ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
    strict:
      "ã‚ãªãŸã¯é«˜æ ¡ã®è‹±èªæ•™å¸«ã§ã™ã€‚æ­£ç¢ºã•ã‚’é‡è¦–ã—ã€è«–ç†çš„ã‹ã¤ç°¡æ½”ã«æŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚",
    friendly:
      "å‹é”ã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã™ã‚‹ã‚ˆã†ãªã€ã‚„ã•ã—ãã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªå£èª¿ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã„ã„ã¨ã“ã‚ã‚’è¤’ã‚ã¾ãã£ã¦ãã ã•ã„ã€‚",
    business:
      "ãƒ•ã‚©ãƒ¼ãƒãƒ«ã§ä¸å¯§ãªè¨€è‘‰ã‚’ä½¿ã„ã€ç¤¾ä¼šäººå‘ã‘ã«æ˜ç¢ºãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã—ã¦ãã ã•ã„ã€‚",
  };

  return toneMap[tone] || toneMap["gentle"];
}

// ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
function generateFeedbackPrompt(text: string, toneInstruction: string): string {
  return `
ä»¥ä¸‹ã®è‹±ä½œæ–‡ã«ã¤ã„ã¦ã€æ–‡ã‚’ä¸€æ–‡ãšã¤å–ã‚Šå‡ºã—ã€æ¬¡ã®å½¢å¼ã§æ·»å‰Šãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼ï¼ˆç¹°ã‚Šè¿”ã—ã¦ãã ã•ã„ï¼‰ï¼š
---
âœï¸ ã‚ãªãŸã®æ–‡: [ç”Ÿå¾’ã®å…ƒã®1æ–‡]
ğŸ§‘â€ğŸ« æ·»å‰Šå¾Œã®æ–‡: [æ–‡æ³•ãƒ»èªå½™ãƒ»è‡ªç„¶ã•ã‚’è€ƒæ…®ã—ãŸæ­£ã—ã„è‹±æ–‡]

ğŸ’¡ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: 
[${toneInstruction}]
---

æœ€å¾Œã«ã€ä»¥ä¸‹ã®è¦³ç‚¹ã§è‹±ä½œæ–‡å…¨ä½“ã®ç·åˆè©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼š
- æ§‹æˆã‚„ã¾ã¨ã¾ã‚Šï¼ˆIntroduction, Body, Conclusionãªã©ï¼‰
- è«–ç†çš„ãªæµã‚Œã‚„ã¤ãªãŒã‚Š
- èªå½™ã‚„è¡¨ç¾ã®å¹…ã€é©åˆ‡ã•
- èª­ã¿æ‰‹ã¸ã®ä¼ã‚ã‚Šã‚„ã™ã•

ä»¥ä¸‹ã®ã‚ˆã†ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

ğŸ“ å…¨ä½“è¬›è©•:
[æ—¥æœ¬èªã§ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¨˜è¼‰]

ã€è‹±ä½œæ–‡ã€‘  
${text}

âš ï¸ æ³¨æ„äº‹é …ï¼š
- æ–‡ã‚’åˆ†å‰²ã—ã¦ä¸€æ–‡ãšã¤æ·»å‰Šã—ã¦ãã ã•ã„ï¼ˆæ–‡ãŒé•·ã„å ´åˆã‚‚é©åˆ‡ã«åˆ†ã‘ã¦ï¼‰
- å…¨ä½“ã§ã¯ãªãã€å„æ–‡ã”ã¨ã«ä¸å¯§ã«ä¿®æ­£ï¼†ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„
- ä¸å¯§ã§ã‚„ã•ã—ã„æ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ï¼ˆä¸­å­¦ç”ŸãŒèª­ã‚€å‰æï¼‰
`;
}

export async function POST(req: NextRequest) {
  try {
    // ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
    const { text, tone } = await req.json();
    const toneInstruction = getToneInstruction(tone);
    const prompt = generateFeedbackPrompt(text, toneInstruction);

    // OpenAIã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    const stream = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [{ role: "user", content: prompt }],
      stream: true,
    });

    const encoder = new TextEncoder();
    
    // å…±é€šã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ä½¿ç”¨
    return createStreamResponse(async (controller) => {
      let accumulatedText = "";
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || "";
        accumulatedText += content;
        controller.enqueue(
          encoder.encode(
            `data: ${JSON.stringify({ feedback: accumulatedText })}\n\n`
          )
        );
      }
      controller.close();
    });
  } catch (error) {
    // å…±é€šã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨
    return handleAPIError(error, "æ·»å‰Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚");
  }
}
